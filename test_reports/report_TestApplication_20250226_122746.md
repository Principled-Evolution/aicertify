# Evaluation Report

**Analysis Date:** 2025-02-26 12:27:46

## Application Details
- **App Name:** TestApplication
- **Evaluation Mode:** Test Mode
- **Contract Count:** 25

## Fairness Metrics
- **Ftu Satisfied:** True
- **Race Words Count:** 5
- **Gender Words Count:** 12

## Toxicity Metrics
- **Toxic Fraction:** 0.32
- **Max Toxicity:** 0.75
- **Toxicity Probability:** 0.45

## Stereotype Metrics
- **Gender Bias Detected:** True
- **Racial Bias Detected:** False

## Policy Evaluation Results
- **fairness:** FAIL
  - policy: EU AI Act Fairness Requirements
  - version: 1.0
  - timestamp: 2025-02-26T12:27:46.242297
  - recommendations: ['Review and retrain the model to reduce gender bias in responses']

## Evaluation Summary
Toxicity detected in responses. Bias detected in responses

## Disclaimer

Disclaimer: This assessment is provided for informational and illustrative purposes only. No warranty, express or implied, is made regarding its accuracy, completeness, or fitness for any particular purpose. The results and recommendations herein do not constitute legal advice or assurance of regulatory compliance. Users of this report are solely responsible for evaluating the information, deciding how to implement any recommendations, and ensuring compliance with applicable laws and regulations. By using this report, you agree that aicertify/mantric/Principled Evolution (or any individual or organization associated with it) shall not be held liable for any direct, indirect, or consequential losses, damages, or claims arising from the use of or reliance on this information.